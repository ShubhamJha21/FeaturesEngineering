{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection based on Mutual Information(Entropy) Gain for classification and Regression problems\n",
    "#### What is Mutual Information?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mutual information of two random variables is a measure of mutual dependence between two variables.The elimination process aims to reduce the size of the input feature set and at the same time to retain the class discriminatory information for classification problems.\n",
    "\n",
    "Mutual information is measure of the amount of information between two random variables is symmetric and non negative, and it could be `zero` if and only if the varibles are independent. \n",
    "    <img src='2.1)Mutual Information.JPG'>\n",
    "\n",
    "ONE PROBLEM EXAMPLE:\n",
    "<IMG src='problem.JPG'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I(A,B) = H(A) - H(A/B)\n",
    "- H(A) = Sum of all(p(ai) * Log Base 2 (1/p(ai)))\n",
    "- for p(ai) we add row values\n",
    "- H(B) = Sum of all(p(bi)* Log Base 2 (1/p(bi)))\n",
    "- p(bi) we add coulum values\n",
    "-  H(A/B) = H(A,B) - H(B)\n",
    "- H(A,B) = Sum of all (p(i)[Log Base 2(1/p(i)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import  train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold,mutual_info_classif,mutual_info_regression\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39205.170000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49278.030000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67333.770000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64007.970000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117310.979016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  var3  var15  imp_ent_var16_ult1  imp_op_var39_comer_ult1  \\\n",
       "0   1     2     23                 0.0                      0.0   \n",
       "1   3     2     34                 0.0                      0.0   \n",
       "2   4     2     23                 0.0                      0.0   \n",
       "3   8     2     37                 0.0                    195.0   \n",
       "4  10     2     39                 0.0                      0.0   \n",
       "\n",
       "   imp_op_var39_comer_ult3  imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
       "0                      0.0                      0.0                      0.0   \n",
       "1                      0.0                      0.0                      0.0   \n",
       "2                      0.0                      0.0                      0.0   \n",
       "3                    195.0                      0.0                      0.0   \n",
       "4                      0.0                      0.0                      0.0   \n",
       "\n",
       "   imp_op_var40_efect_ult1  imp_op_var40_efect_ult3  ...  \\\n",
       "0                        0                        0  ...   \n",
       "1                        0                        0  ...   \n",
       "2                        0                        0  ...   \n",
       "3                        0                        0  ...   \n",
       "4                        0                        0  ...   \n",
       "\n",
       "   saldo_medio_var33_hace2  saldo_medio_var33_hace3  saldo_medio_var33_ult1  \\\n",
       "0                      0.0                      0.0                     0.0   \n",
       "1                      0.0                      0.0                     0.0   \n",
       "2                      0.0                      0.0                     0.0   \n",
       "3                      0.0                      0.0                     0.0   \n",
       "4                      0.0                      0.0                     0.0   \n",
       "\n",
       "   saldo_medio_var33_ult3  saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
       "0                     0.0                      0.0                      0.0   \n",
       "1                     0.0                      0.0                      0.0   \n",
       "2                     0.0                      0.0                      0.0   \n",
       "3                     0.0                      0.0                      0.0   \n",
       "4                     0.0                      0.0                      0.0   \n",
       "\n",
       "   saldo_medio_var44_ult1  saldo_medio_var44_ult3          var38  TARGET  \n",
       "0                     0.0                     0.0   39205.170000       0  \n",
       "1                     0.0                     0.0   49278.030000       0  \n",
       "2                     0.0                     0.0   67333.770000       0  \n",
       "3                     0.0                     0.0   64007.970000       0  \n",
       "4                     0.0                     0.0  117310.979016       0  \n",
       "\n",
       "[5 rows x 371 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('santander-train.csv',nrows=20000)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('TARGET',axis=1)\n",
    "y = data['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20000, 370), (20000,))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.20,random_state=1,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16000, 370), (4000, 370))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove constant,quasi constant and duplicate features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constant Removal,Passing a value of zero for the parameter will filter all the features with zero variance. Execute the following script to create a filter for constant features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VarianceThreshold(threshold=0)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constant_filter = VarianceThreshold(threshold=0)\n",
    "constant_filter.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True, False, False,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True, False, False,  True,  True,  True,  True,  True, False,\n",
       "       False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True, False, False, False, False,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False,  True,  True,  True, False, False,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True, False, False,  True,  True,  True,\n",
       "        True,  True, False, False,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True, False, False, False,\n",
       "       False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True, False, False,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "       False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "       False, False,  True,  True,  True,  True,  True, False,  True,\n",
       "        True, False,  True,  True, False,  True, False, False,  True,\n",
       "        True,  True,  True,  True,  True, False,  True, False,  True,\n",
       "       False,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "        True, False,  True, False,  True, False, False, False, False,\n",
       "        True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "        True, False,  True, False,  True, False, False,  True,  True,\n",
       "       False,  True, False, False, False,  True, False, False,  True,\n",
       "        True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True, False, False,  True,  True,  True,  True,  True,  True,\n",
       "       False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "       False,  True, False, False,  True,  True,  True,  True, False,\n",
       "        True, False, False, False,  True, False, False,  True,  True,\n",
       "        True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True, False, False,\n",
       "       False, False,  True,  True,  True,  True,  True, False,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show all results True that is not constant\n",
    "constant_filter.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constant_filter.get_support().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "constant_list = [not temp for temp in constant_filter.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constant feature list\n",
    "# X.columns[constant_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16000, 290), (4000, 290))"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_not_constant = constant_filter.transform(X_train)\n",
    "X_test_not_constant = constant_filter.transform(X_test)\n",
    "X_train_not_constant.shape,X_test_not_constant.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "370-290"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We successfuly removed 80 features that are constant. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now we will remove quasi constant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "quasi_ConstantFilter = VarianceThreshold(threshold=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "quasi_ConstantFilter.fit(X_train_not_constant)\n",
    "X_train_new = quasi_ConstantFilter.transform(X_train_not_constant)\n",
    "X_test_new = quasi_ConstantFilter.transform(X_test_not_constant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new = pd.DataFrame(X_train_new)\n",
    "X_test_new = pd.DataFrame(X_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>236</th>\n",
       "      <th>237</th>\n",
       "      <th>238</th>\n",
       "      <th>239</th>\n",
       "      <th>240</th>\n",
       "      <th>241</th>\n",
       "      <th>242</th>\n",
       "      <th>243</th>\n",
       "      <th>244</th>\n",
       "      <th>245</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94956.660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9580.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.42</td>\n",
       "      <td>483.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117310.979016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22549.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>103.71</td>\n",
       "      <td>164.91</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62614.290000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5400.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47024.610000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21274.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65467.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15995</th>\n",
       "      <td>36162.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101460.780000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15996</th>\n",
       "      <td>6849.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48378.690000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15997</th>\n",
       "      <td>30145.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>292785.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15998</th>\n",
       "      <td>37855.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>144.39</td>\n",
       "      <td>280.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117310.979016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15999</th>\n",
       "      <td>19872.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91452.540000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16000 rows Ã— 246 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0    1     2    3       4       5    6    7    8    9    ...  236  \\\n",
       "0         14.0  2.0  27.0  0.0    0.00    0.00  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "1       9580.0  2.0  38.0  0.0   69.42  483.30  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "2      22549.0  2.0  52.0  0.0  103.71  164.91  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "3       5400.0  2.0  39.0  0.0    0.00    0.00  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "4      21274.0  2.0  25.0  0.0    0.00    0.00  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "...        ...  ...   ...  ...     ...     ...  ...  ...  ...  ...  ...  ...   \n",
       "15995  36162.0  2.0  35.0  0.0    0.00    0.00  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "15996   6849.0  2.0  38.0  0.0    0.00    0.00  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "15997  30145.0  2.0  23.0  0.0    0.00    0.00  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "15998  37855.0  2.0  23.0  0.0  144.39  280.53  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "15999  19872.0  2.0  45.0  0.0    0.00    0.00  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "\n",
       "       237  238  239  240  241  242  243  244            245  \n",
       "0      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   94956.660000  \n",
       "1      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  117310.979016  \n",
       "2      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   62614.290000  \n",
       "3      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   47024.610000  \n",
       "4      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   65467.950000  \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...            ...  \n",
       "15995  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  101460.780000  \n",
       "15996  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   48378.690000  \n",
       "15997  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  292785.330000  \n",
       "15998  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  117310.979016  \n",
       "15999  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   91452.540000  \n",
       "\n",
       "[16000 rows x 246 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44, 124)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "290-246,370-246"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We removed 44 quasi_constant features also and total 124 features have removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Duplicate Feature(100% similar value)\n",
    "\n",
    "SKlearn has no direct library to handle duplicate value but python has method to separate duplicate rows so for this we first we convert all columns into rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_T = X_train_new.T\n",
    "X_test_T = X_test_new.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15990</th>\n",
       "      <th>15991</th>\n",
       "      <th>15992</th>\n",
       "      <th>15993</th>\n",
       "      <th>15994</th>\n",
       "      <th>15995</th>\n",
       "      <th>15996</th>\n",
       "      <th>15997</th>\n",
       "      <th>15998</th>\n",
       "      <th>15999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.00</td>\n",
       "      <td>9580.000000</td>\n",
       "      <td>22549.00</td>\n",
       "      <td>5400.00</td>\n",
       "      <td>21274.00</td>\n",
       "      <td>28648.000000</td>\n",
       "      <td>17005.000000</td>\n",
       "      <td>37420.00</td>\n",
       "      <td>25926.0</td>\n",
       "      <td>5809.00</td>\n",
       "      <td>...</td>\n",
       "      <td>18868.000000</td>\n",
       "      <td>5914.00</td>\n",
       "      <td>20826.00</td>\n",
       "      <td>17575.00</td>\n",
       "      <td>25488.00</td>\n",
       "      <td>36162.00</td>\n",
       "      <td>6849.00</td>\n",
       "      <td>30145.00</td>\n",
       "      <td>37855.000000</td>\n",
       "      <td>19872.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.00</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27.00</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>52.00</td>\n",
       "      <td>39.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>25.00</td>\n",
       "      <td>24.0</td>\n",
       "      <td>26.00</td>\n",
       "      <td>...</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>42.00</td>\n",
       "      <td>51.00</td>\n",
       "      <td>38.00</td>\n",
       "      <td>23.00</td>\n",
       "      <td>35.00</td>\n",
       "      <td>38.00</td>\n",
       "      <td>23.00</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>45.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>69.420000</td>\n",
       "      <td>103.71</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>239.85</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>144.390000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>94956.66</td>\n",
       "      <td>117310.979016</td>\n",
       "      <td>62614.29</td>\n",
       "      <td>47024.61</td>\n",
       "      <td>65467.95</td>\n",
       "      <td>117310.979016</td>\n",
       "      <td>117310.979016</td>\n",
       "      <td>65837.22</td>\n",
       "      <td>51091.8</td>\n",
       "      <td>75931.11</td>\n",
       "      <td>...</td>\n",
       "      <td>117310.979016</td>\n",
       "      <td>68238.39</td>\n",
       "      <td>80366.55</td>\n",
       "      <td>66311.88</td>\n",
       "      <td>28763.58</td>\n",
       "      <td>101460.78</td>\n",
       "      <td>48378.69</td>\n",
       "      <td>292785.33</td>\n",
       "      <td>117310.979016</td>\n",
       "      <td>91452.54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>246 rows Ã— 16000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0              1         2         3         4              5      \\\n",
       "0       14.00    9580.000000  22549.00   5400.00  21274.00   28648.000000   \n",
       "1        2.00       2.000000      2.00      2.00      2.00       2.000000   \n",
       "2       27.00      38.000000     52.00     39.00     25.00      23.000000   \n",
       "3        0.00       0.000000      0.00      0.00      0.00       0.000000   \n",
       "4        0.00      69.420000    103.71      0.00      0.00       0.000000   \n",
       "..        ...            ...       ...       ...       ...            ...   \n",
       "241      0.00       0.000000      0.00      0.00      0.00       0.000000   \n",
       "242      0.00       0.000000      0.00      0.00      0.00       0.000000   \n",
       "243      0.00       0.000000      0.00      0.00      0.00       0.000000   \n",
       "244      0.00       0.000000      0.00      0.00      0.00       0.000000   \n",
       "245  94956.66  117310.979016  62614.29  47024.61  65467.95  117310.979016   \n",
       "\n",
       "             6         7        8         9      ...          15990     15991  \\\n",
       "0     17005.000000  37420.00  25926.0   5809.00  ...   18868.000000   5914.00   \n",
       "1         2.000000      2.00      2.0      2.00  ...       2.000000      2.00   \n",
       "2        26.000000     25.00     24.0     26.00  ...      27.000000     42.00   \n",
       "3         0.000000      0.00      0.0      0.00  ...       0.000000      0.00   \n",
       "4         0.000000      0.00      0.0    239.85  ...       0.000000      0.00   \n",
       "..             ...       ...      ...       ...  ...            ...       ...   \n",
       "241       0.000000      0.00      0.0      0.00  ...       0.000000      0.00   \n",
       "242       0.000000      0.00      0.0      0.00  ...       0.000000      0.00   \n",
       "243       0.000000      0.00      0.0      0.00  ...       0.000000      0.00   \n",
       "244       0.000000      0.00      0.0      0.00  ...       0.000000      0.00   \n",
       "245  117310.979016  65837.22  51091.8  75931.11  ...  117310.979016  68238.39   \n",
       "\n",
       "        15992     15993     15994      15995     15996      15997  \\\n",
       "0    20826.00  17575.00  25488.00   36162.00   6849.00   30145.00   \n",
       "1        2.00      2.00      2.00       2.00      2.00       2.00   \n",
       "2       51.00     38.00     23.00      35.00     38.00      23.00   \n",
       "3        0.00      0.00      0.00       0.00      0.00       0.00   \n",
       "4        0.00      0.00      0.00       0.00      0.00       0.00   \n",
       "..        ...       ...       ...        ...       ...        ...   \n",
       "241      0.00      0.00      0.00       0.00      0.00       0.00   \n",
       "242      0.00      0.00      0.00       0.00      0.00       0.00   \n",
       "243      0.00      0.00      0.00       0.00      0.00       0.00   \n",
       "244      0.00      0.00      0.00       0.00      0.00       0.00   \n",
       "245  80366.55  66311.88  28763.58  101460.78  48378.69  292785.33   \n",
       "\n",
       "             15998     15999  \n",
       "0     37855.000000  19872.00  \n",
       "1         2.000000      2.00  \n",
       "2        23.000000     45.00  \n",
       "3         0.000000      0.00  \n",
       "4       144.390000      0.00  \n",
       "..             ...       ...  \n",
       "241       0.000000      0.00  \n",
       "242       0.000000      0.00  \n",
       "243       0.000000      0.00  \n",
       "244       0.000000      0.00  \n",
       "245  117310.979016  91452.54  \n",
       "\n",
       "[246 rows x 16000 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_T.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      False\n",
       "1      False\n",
       "2      False\n",
       "3      False\n",
       "4      False\n",
       "       ...  \n",
       "241    False\n",
       "242    False\n",
       "243    False\n",
       "244    False\n",
       "245    False\n",
       "Length: 246, dtype: bool"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicated_feature = X_train_T.duplicated()\n",
    "duplicated_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature_to_keep = [not temp for temp in duplicated_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_unique = X_train_T[Feature_to_keep].T\n",
    "X_test_unique = X_test_T[Feature_to_keep].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16000, 227), (4000, 227))"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_unique.shape,X_test_unique.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 370)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "370-227"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "143 constant, quasi-constant, duplicated features are successfuly removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Mutual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi = mutual_info_classif(X_train_unique,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.18884868e-04 5.83403442e-04 1.17183232e-02 0.00000000e+00\n",
      " 8.64620138e-04 8.86046241e-04 6.05242205e-04 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 2.40670627e-03 0.00000000e+00\n",
      " 2.39682559e-04 1.47273646e-04 4.20404283e-04 0.00000000e+00\n",
      " 1.54372113e-03 1.26310513e-03 1.46257733e-03 0.00000000e+00\n",
      " 0.00000000e+00 2.79826696e-03 8.50266624e-03 5.36912179e-04\n",
      " 3.18906715e-04 2.20579197e-03 5.30249330e-04 2.51697393e-03\n",
      " 6.28022545e-04 3.02450693e-03 1.84731013e-03 2.35734329e-03\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 3.29949757e-04 8.87096400e-03 1.39424398e-03\n",
      " 0.00000000e+00 3.21489406e-03 2.65578959e-03 2.27863117e-03\n",
      " 0.00000000e+00 1.05166967e-02 3.73642237e-03 9.47896509e-03\n",
      " 0.00000000e+00 0.00000000e+00 3.41985957e-03 6.68807464e-04\n",
      " 2.45592588e-03 1.11101545e-03 1.70289196e-03 1.48309767e-03\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 2.13538145e-04 0.00000000e+00 4.04332505e-04 8.52946295e-04\n",
      " 2.40515908e-03 8.59435020e-04 7.35220838e-04 0.00000000e+00\n",
      " 1.20053672e-03 1.21468159e-03 0.00000000e+00 9.91533371e-04\n",
      " 4.61492331e-04 0.00000000e+00 4.45928015e-04 4.33996349e-04\n",
      " 1.84968470e-03 0.00000000e+00 4.41456438e-03 9.78591986e-03\n",
      " 0.00000000e+00 0.00000000e+00 1.74022047e-03 6.94260586e-04\n",
      " 1.25270831e-02 1.99912197e-03 9.13511992e-04 2.66380683e-03\n",
      " 5.47687225e-03 3.62843079e-03 9.65934652e-03 7.51006306e-04\n",
      " 4.21690799e-04 0.00000000e+00 8.49715331e-03 0.00000000e+00\n",
      " 0.00000000e+00 6.42459253e-04 4.15739970e-04 4.45190717e-04\n",
      " 1.04901662e-03 0.00000000e+00 0.00000000e+00 8.96226452e-04\n",
      " 1.91819063e-03 9.46317557e-04 1.20228428e-03 1.30401587e-02\n",
      " 0.00000000e+00 0.00000000e+00 4.23818592e-03 4.14998728e-04\n",
      " 1.11355204e-02 2.24587626e-03 6.22591478e-03 0.00000000e+00\n",
      " 8.74695580e-04 3.70359707e-03 2.97699324e-03 1.98508081e-03\n",
      " 0.00000000e+00 0.00000000e+00 6.03381906e-05 6.94025799e-04\n",
      " 0.00000000e+00 0.00000000e+00 1.87290111e-03 0.00000000e+00\n",
      " 2.44162615e-04 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 2.37188031e-04 1.80877030e-03\n",
      " 0.00000000e+00 4.19496501e-04 6.46956198e-04 0.00000000e+00\n",
      " 1.83877231e-04 1.73062026e-03 0.00000000e+00 0.00000000e+00\n",
      " 1.14378255e-03 2.76689956e-03 6.93623696e-05 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 3.00709104e-03 0.00000000e+00\n",
      " 2.54951672e-04 0.00000000e+00 1.07765745e-03 0.00000000e+00\n",
      " 7.17917216e-04 0.00000000e+00 1.34384453e-03 0.00000000e+00\n",
      " 1.77274019e-04 0.00000000e+00 1.42705969e-03 1.14876774e-03\n",
      " 1.11949086e-02 0.00000000e+00 0.00000000e+00 1.39009745e-04\n",
      " 1.83035694e-03 3.69592358e-03 1.16551508e-03 0.00000000e+00\n",
      " 5.33247156e-04 7.64363305e-04 7.73308721e-04 4.11004394e-03\n",
      " 6.33832812e-04 1.12134574e-04 5.36499662e-04 5.14455060e-04\n",
      " 8.82380373e-04 1.36980043e-03 3.57843345e-04 1.96491838e-03\n",
      " 1.07566439e-03 0.00000000e+00 5.15866371e-04 0.00000000e+00\n",
      " 0.00000000e+00 2.42394002e-03 8.95106671e-04 9.20384683e-03\n",
      " 7.69046940e-03 9.60128118e-03 8.85501456e-03 2.39149548e-03\n",
      " 7.09049596e-05 1.95623989e-04 1.63211153e-03 1.05850153e-03\n",
      " 1.83225751e-03 1.77630289e-03 1.03502986e-03 0.00000000e+00\n",
      " 0.00000000e+00 3.90039112e-05 2.41111238e-03 1.40071293e-03\n",
      " 1.68175027e-03 6.58848532e-05 0.00000000e+00 1.32527633e-03\n",
      " 0.00000000e+00 1.17895158e-03 1.71804542e-03 1.53738918e-03\n",
      " 4.15676256e-04 0.00000000e+00 7.16774965e-05 2.08366303e-03\n",
      " 0.00000000e+00 0.00000000e+00 1.68123068e-03 0.00000000e+00\n",
      " 0.00000000e+00 1.99331355e-03 2.20719543e-03]\n"
     ]
    }
   ],
   "source": [
    "print(mi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi = pd.Series(mi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.000219\n",
       "1      0.000583\n",
       "2      0.011718\n",
       "3      0.000000\n",
       "4      0.000865\n",
       "         ...   \n",
       "222    0.001681\n",
       "223    0.000000\n",
       "224    0.000000\n",
       "225    0.001993\n",
       "226    0.002207\n",
       "Length: 227, dtype: float64"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi.index = X_train_unique.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n",
       "            ...\n",
       "            236, 237, 238, 239, 240, 241, 242, 243, 244, 245],\n",
       "           dtype='int64', length=227)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi.sort_values(ascending=False,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1cc37d60>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mi.plot.bar(figsize=(16,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that after almost 60% on x axis features have zero mutual information that means yet in groups these feature play a vital role but individualy in a univariate method these features have not any impact in training dataset or enough information for classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  creat a features percentage selector\n",
    "sel = SelectPercentile(mutual_info_classif,percentile=10).fit(X_train_unique,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([  2,  21,  22,  40,  49,  50,  51,  85,  86,  92, 101, 102, 106,\n",
       "            120, 126, 128, 129, 183, 210, 211, 212, 213, 225],\n",
       "           dtype='int64')"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_unique.columns[sel.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_unique.columns[sel.get_support()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on SelectPercentile in module sklearn.feature_selection._univariate_selection object:\n",
      "\n",
      "class SelectPercentile(_BaseFilter)\n",
      " |  SelectPercentile(score_func=<function f_classif at 0x1BF164A8>, percentile=10)\n",
      " |  \n",
      " |  Select features according to a percentile of the highest scores.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <univariate_feature_selection>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  score_func : callable\n",
      " |      Function taking two arrays X and y, and returning a pair of arrays\n",
      " |      (scores, pvalues) or a single array with scores.\n",
      " |      Default is f_classif (see below \"See also\"). The default function only\n",
      " |      works with classification tasks.\n",
      " |  \n",
      " |  percentile : int, optional, default=10\n",
      " |      Percent of features to keep.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  scores_ : array-like of shape (n_features,)\n",
      " |      Scores of features.\n",
      " |  \n",
      " |  pvalues_ : array-like of shape (n_features,)\n",
      " |      p-values of feature scores, None if `score_func` returned only scores.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.datasets import load_digits\n",
      " |  >>> from sklearn.feature_selection import SelectPercentile, chi2\n",
      " |  >>> X, y = load_digits(return_X_y=True)\n",
      " |  >>> X.shape\n",
      " |  (1797, 64)\n",
      " |  >>> X_new = SelectPercentile(chi2, percentile=10).fit_transform(X, y)\n",
      " |  >>> X_new.shape\n",
      " |  (1797, 7)\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  Ties between features with equal scores will be broken in an unspecified\n",
      " |  way.\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  f_classif: ANOVA F-value between label/feature for classification tasks.\n",
      " |  mutual_info_classif: Mutual information for a discrete target.\n",
      " |  chi2: Chi-squared stats of non-negative features for classification tasks.\n",
      " |  f_regression: F-value between label/feature for regression tasks.\n",
      " |  mutual_info_regression: Mutual information for a continuous target.\n",
      " |  SelectKBest: Select features based on the k highest scores.\n",
      " |  SelectFpr: Select features based on a false positive rate test.\n",
      " |  SelectFdr: Select features based on an estimated false discovery rate.\n",
      " |  SelectFwe: Select features based on family-wise error rate.\n",
      " |  GenericUnivariateSelect: Univariate feature selector with configurable mode.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      SelectPercentile\n",
      " |      _BaseFilter\n",
      " |      sklearn.feature_selection._base.SelectorMixin\n",
      " |      sklearn.base.TransformerMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, score_func=<function f_classif at 0x1BF164A8>, percentile=10)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from _BaseFilter:\n",
      " |  \n",
      " |  fit(self, X, y)\n",
      " |      Run score function on (X, y) and get the appropriate features.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          The training input samples.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,)\n",
      " |          The target values (class labels in classification, real numbers in\n",
      " |          regression).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.feature_selection._base.SelectorMixin:\n",
      " |  \n",
      " |  get_support(self, indices=False)\n",
      " |      Get a mask, or integer index, of the features selected\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      indices : boolean (default False)\n",
      " |          If True, the return value will be an array of integers, rather\n",
      " |          than a boolean mask.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      support : array\n",
      " |          An index that selects the retained features from a feature vector.\n",
      " |          If `indices` is False, this is a boolean array of shape\n",
      " |          [# input features], in which an element is True iff its\n",
      " |          corresponding feature is selected for retention. If `indices` is\n",
      " |          True, this is an integer array of shape [# output features] whose\n",
      " |          values are indices into the input feature vector.\n",
      " |  \n",
      " |  inverse_transform(self, X)\n",
      " |      Reverse the transformation operation\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array of shape [n_samples, n_selected_features]\n",
      " |          The input samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_r : array of shape [n_samples, n_original_features]\n",
      " |          `X` with columns of zeros inserted where features would have\n",
      " |          been removed by :meth:`transform`.\n",
      " |  \n",
      " |  transform(self, X)\n",
      " |      Reduce X to the selected features.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array of shape [n_samples, n_features]\n",
      " |          The input samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_r : array of shape [n_samples, n_selected_features]\n",
      " |          The input samples with only the selected features.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.TransformerMixin:\n",
      " |  \n",
      " |  fit_transform(self, X, y=None, **fit_params)\n",
      " |      Fit to data, then transform it.\n",
      " |      \n",
      " |      Fits transformer to X and y with optional parameters fit_params\n",
      " |      and returns a transformed version of X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : numpy array of shape [n_samples, n_features]\n",
      " |          Training set.\n",
      " |      \n",
      " |      y : numpy array of shape [n_samples]\n",
      " |          Target values.\n",
      " |      \n",
      " |      **fit_params : dict\n",
      " |          Additional fit parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_new : numpy array of shape [n_samples, n_features_new]\n",
      " |          Transformed array.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.TransformerMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mi = sel.transform(X_train_unique)\n",
    "X_test_mi = sel.transform(X_test_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16000, 23), (4000, 23))"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_mi.shape,X_test_mi.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model and compare the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_randomForest(X_train,X_test,y_train,y_test):\n",
    "    clf = RandomForestClassifier(n_estimators=100,random_state=0,n_jobs=-1)\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print('Accuracy On Test Set:')\n",
    "    print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy On Test Set:\n",
      "0.958\n",
      "Wall time: 1.99 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "run_randomForest(X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy On Test Set:\n",
      "0.958\n",
      "Wall time: 1.33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "run_randomForest(X_train_unique,X_test_unique,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy On Test Set:\n",
      "0.95775\n",
      "Wall time: 444 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "run_randomForest(X_train_mi,X_test_mi,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77.68844221105527"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1.99-0.444)*100/1.99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bam! one clap for your's we reduce too much training time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutual information gain in Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'feature_names', 'DESCR', 'filename'])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a DataFrame using this boston data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  \n",
       "4     18.7  396.90   5.33  "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.DataFrame(data=boston.data,columns=boston.feature_names)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.20,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi = mutual_info_regression(X_train,y_train)\n",
    "mi = pd.Series(mi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX',\n",
       "       'PTRATIO', 'B', 'LSTAT'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi.index = X_train.columns\n",
    "mi.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       0.351305\n",
       "ZN         0.199473\n",
       "INDUS      0.511599\n",
       "CHAS       0.019293\n",
       "NOX        0.454419\n",
       "RM         0.561597\n",
       "AGE        0.342796\n",
       "DIS        0.320216\n",
       "RAD        0.216069\n",
       "TAX        0.392735\n",
       "PTRATIO    0.490620\n",
       "B          0.147071\n",
       "LSTAT      0.681849\n",
       "dtype: float64"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi.sort_values(ascending=False,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTAT      0.681849\n",
       "RM         0.561597\n",
       "INDUS      0.511599\n",
       "PTRATIO    0.490620\n",
       "NOX        0.454419\n",
       "TAX        0.392735\n",
       "CRIM       0.351305\n",
       "AGE        0.342796\n",
       "DIS        0.320216\n",
       "RAD        0.216069\n",
       "ZN         0.199473\n",
       "B          0.147071\n",
       "CHAS       0.019293\n",
       "dtype: float64"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x28419460>"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mi.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CRIM', 'INDUS', 'NOX', 'RM', 'AGE', 'DIS', 'TAX', 'PTRATIO', 'LSTAT'], dtype='object')"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel = SelectKBest(mutual_info_regression,k=9).fit(X_train,y_train)\n",
    "X_train.columns[sel.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train,y_train)\n",
    "y_predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5892223849182503"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.783509315085138"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.188011545278203"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standard Deviation of house price \n",
    "np.std(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### r2_score and Standard Deviation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404, 9)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_9 = sel.transform(X_train)\n",
    "X_train_9.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102, 9)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_9 = sel.transform(X_test)\n",
    "X_test_9.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = LinearRegression()\n",
    "model.fit(X_train_9,y_train)\n",
    "y_predict_9 = model.predict(X_test_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5317127606961575"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,y_predict_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.783509315085138"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('MSE:')\n",
    "np.sqrt(mean_squared_error(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
